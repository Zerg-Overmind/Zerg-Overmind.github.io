<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Quankai Gao (郜泉凯) </title>
  
  
  <meta name="author" content="Quankai Gao(郜泉凯)">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/none.png">
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name> Quankai Gao(郜泉凯)</name>
                                 

         
              
             <p>I am a second-year Ph.D. student in Computer Science department at the University of Southern California, advised by Prof.<a href="https://scholar.google.com/citations?user=MHet2VoAAAAJ&hl=en">Ulrich Neumann</a>.
		         Before coming to USC, I earned my B.E. in Automation Science and Engineering from South China University of Technology.
             </p>
               <br>
              <p>My research interests lie at computer vision and computer graphics including 3D geometry, scene understanding and 3D human face analysis and generation. </p>
              
              <br>
              <p style="text-align:center">
                <a href="mailto:quankaig@usc.edu">Email</a> &nbsp/&nbsp
                <a href="https://zerg-overmind.github.io/">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=tIdThSIAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/Zerg-Overmind/">Github</a>
                
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/me.jpg"><img style="width:80%;max-width:100%" alt="profile photo" src="images/me.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
          
  
         <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Experience</heading>
              <p>
               <strong>Google</strong>
	       </br>Student Researcher, 2023
		</br> 
              </p>
	    
              <p>
               <strong>Robotics Institute, Carnegie Mellon University</strong>, USA
	       </br>Research Assistant, 2021 to 2022
	       </br>Advisor: Prof.<a href="https://scholar.google.com/citations?user=YB8_6gkAAAAJ&hl=zh-CN">Fernando De La Torre</a>
               </br>—3D huamn face generation with disentanglement and granular control between identity and expression.
		</br> 
              </p>
	
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Awards and Honors</heading>
              <p>
		  GSG Professional Development Fund, University of Southern California. 2023    
               </br> First Prize, The Chinese Mathematics Competitions (CMC), Guangdong. 2018
	       </br> Finalist Winner, Mathematical Contest in Modeling (MCM/ICM), COMAP. 2018
	       </br> National Scholarship. 2018 
               </br> Scholarship of South China University of Technology. 2016, 2017.
		</br> 
              </p>
	
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
	
	</td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
 
         <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Teaching</heading>
              <p>
               Teaching Assistant, CSCI 585 Database Systems
		</br> 
              </p>
	
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
		
	</td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
 
         <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Academic Services</heading>
              <p>
               Reviewer of the following conferences/journals: 
		<p>
               <strong>ECCV</strong>, <strong>CVPR</strong>, <strong>TIP</strong>
              </p>
              </p>
	
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
		
		

            </td>
          </tr>
        </tbody></table>

        <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publication</heading>
	      <p>
               *denotes equal contribution
              </p>

		<p>
               	MagicPose: Realistic Human Poses and Facial Expressions Retargeting with Identity-aware Diffusion.
	      </br> Di Chang, Yichun Shi, <strong>Quankai Gao</strong>, Jessica Fu, Hongyi Xu, Guoxian Song, Qing Yan, Yizhe Zhu, Xiao Yang, Mohammad Soleymani  
              </br>[<a href="https://arxiv.org/pdf/2311.12052">Paper</a>] [<a href="https://github.com/Boese0601/MagicDance">Code</a>] [<a href="https://boese0601.github.io/magicdance/">Project Page</a>]      
              </br>
              International Conference on Machine Learning (ICML), 2024.
              <br>
              </p> 
		    
               <p>
               Stratified Avatar Generation from Sparse Observations
	       </br> Han Feng*, Wenchao Ma*, <strong>Quankai Gao</strong>, Xianwei Zheng, Nan Xue, Huijuan Xu  
              </br>[<a href="https://fhan235.github.io/SAGENet/">Paper</a>] [<a href="https://fhan235.github.io/SAGENet/">Code</a>] [<a href="https://fhan235.github.io/SAGENet/">Project Page</a>]      
              </br>
              Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (<em>CVPR</em>), 2024 <font color="#FF0000">(Oral)</font>
              <br>
              </p> 
	
               <p>
               InSpaceType: Reconsider Space Type in Indoor Monocular Depth Estimation
	       </br>Cho-Ying Wu, <strong>Quankai Gao</strong>, Chin-Cheng Hsu, Te-Lin Wu, Jing-Wen Chen, Ulrich Neumann 
              </br>[<a href="https://arxiv.org/abs/2309.13516">Paper</a>] [<a href="https://github.com/DepthComputation/InSpaceType_Benchmark">Code</a>] [<a href="https://depthcomputation.github.io/DepthPublic/">Project Page</a>]      
              </br>
              Conference on Robot Learning (CoRL) OOD Workshop, 2023  
              <br>
              </p> 
		    
              <p>
               Strivec: Sparse Tri-Vector Radiance Fields
	       </br><strong>Quankai Gao*</strong>, Qiangeng Xu*, Hao Su, Ulrich Neumann, Zexiang Xu 
              </br>[<a href="https://arxiv.org/abs/2307.13226">Paper</a>] [<a href="https://github.com/Zerg-Overmind/Strivec">Code</a>] [<a href="https://github.com/Zerg-Overmind/Strivec">Project Page</a>]      
              </br>
              Proceedings of the IEEE International Conference on Computer Vision (<em>ICCV</em>), 2023  
              <br>
              </p> 
		    
	      <p>
               Controllable 3D Generative Adversarial Face Model via Disentangling Shape and Appearance
	       </br>Fariborz Taherkhan, Aashish Rai*, <strong>Quankai Gao*</strong>, Shaunak Srivastava*, Xuanbai Chen, Fernando de la Torre, Steven Song, Aayush Prakash, Daeil Kim 
              </br>[<a href="https://arxiv.org/pdf/2208.14263.pdf">Paper</a>] [<a href="https://github.com/aashishrai3799/3DFaceCAM">Code</a>] [<a href="https://aashishrai3799.github.io/3DFaceCAM/">Project Page</a>]   
              </br>
              Winter Conference on Applications of Computer Vision (<em>WACV</em>), 2023  
              <br>
              </p> 
         
              <p>
               Deep Graph Matching under Quadratic Constraint
	       </br><strong>Quankai Gao</strong>, Fudong Wang, Nan Xue, Jin-Gang Yu, Gui-Song Xia
               </br>[<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Gao_Deep_Graph_Matching_Under_Quadratic_Constraint_CVPR_2021_paper.pdf">Paper</a>] [<a href="https://github.com/Zerg-Overmind/QC-DGM">Code</a>]
              </br>
              Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (<em>CVPR</em>), 2021  
              <br>
              </p>
              
        
        
           

              
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>   
           
  
